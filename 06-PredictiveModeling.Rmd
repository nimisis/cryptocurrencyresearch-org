# Predictive Modeling {#predictive-modeling}

We finally have everything we need to start making predictive models now that the [data has been cleaned](#data-prep) and we have come up with a [gameplan to understand the efficacy of the models](#model-validation-plan).

## Example Simple Model {#example-simple-model}

We can start by making a simple [**linear regression** model](https://en.wikipedia.org/wiki/Linear_regression):

```{r lm_model, class.output="scroll-lim"}
lm(formula = target_price_24h ~ ., data = cryptodata)
```

We defined the [**formula**]{style="color: blue;"} for the model as **`target_price_24h ~ .`**, which means that we are want to make predictions for the [**target_price_24h**]{style="color: blue;"} field, and use (**`~`**) every other column found in the data (**`.`**). In other words, we specified a model that uses the [**target_price_24h**]{style="color: blue;"} field as the [dependent variable](https://en.wikipedia.org/wiki/Dependent_and_independent_variables), and all other columns (**`.`**) as the [independent variables](https://en.wikipedia.org/wiki/Dependent_and_independent_variables). Meaning, we are looking to predict the [**target_price_24h**]{style="color: blue;"}, which is the only column that refers to the future, and use all the information available at the time the rest of the data was collected in order to infer statistical relationships that can help us forecast the future values of the [**target_price_24h**]{style="color: blue;"} field when it is still unknown on new data that we want to make new predictions for.

In the example above we used the [**cryptodata**]{style="color: blue;"} object which contained all the non-nested data, and was a big oversimplification of the process we will actually use. 

### Using Functional Programming {#using-functional-programming}

<!-- [TODO - Explain here] -->

```{r}
linear_model <- function(df){
  lm(target_price_24h ~ . -date_time_utc -date, data = df)
}
```

Can now use it for `map()`

```{r}
cryptodata_nested %>% mutate(lm_model = map(train_data, linear_model))
```

## Caret

### Parallel Processing

[ADD HERE About R only using one CPU as deafault but can use more enabling parallel processing]

```{r parallel_processing}
library(doParallel)
cl <- makePSOCKcluster(12)
registerDoParallel(cl)
```

### Functional Programming - here or elsewhere?

[ADD HERE]

Here use Caret + purrr to make models

```{r}
linear_model_caret <- function(df){

  train(target_price_24h ~ . -date_time_utc -date, data = df,
        method = 'lm',
        trControl=trainControl(method="none"))

}
```

Can now use it for `map()`

```{r}
cryptodata_nested <- mutate(cryptodata_nested, 
                            lm_model = map(train_data, linear_model_caret))
```

### Cross Validation {#cross-validation-preds}

Within each split we created, we can set caret to perform an additional cross-validation step to allow it to do a minimal level of automated hyperparameter tuning as it creates the models (the more we do the longer it will take).

```{r}
fitControl <- trainControl(method = "repeatedcv",
                           number = 3,
                           repeats = 3)
```

<!-- [TODO - here need to explain "method" options like I did in the high-level version (use those images)] -->

Now create more generalized version

```{r}
model_caret <- function(df, method_choice){

  train(target_price_24h ~ . -date_time_utc -date, data = df,
        method = method_choice,
        trControl=fitControl)

}
```

### XGBoost models

Will now need to use map2()

```{r}
cryptodata_nested <- mutate(cryptodata_nested, 
                            xgb_model = map2(train_data, "xgbLinear", model_caret))
```

Can also make a tree based XGBoost model:

```{r}
cryptodata_nested <- mutate(cryptodata_nested, 
                            xgbTree_model = map2(train_data, "xgbTree", model_caret))
```

[TODO - Reference xgboost documentation. Can I embed it? <https://xgboost.readthedocs.io/en/latest/parameter.html>]

### All Other Models

Can use the same function and methodology to keep adding models. Could also all be done in one step adding more arguments to `mutate()`, but broken up to be verbose and take it step by step.

#### Neural Network models

```{r}
cryptodata_nested <- mutate(cryptodata_nested, 
                            nnet_model = map2(train_data, "dnn", model_caret))
```

#### Gradient Boosting Machines

<!-- ```{r} -->

<!-- cryptodata_nested <- mutate(cryptodata_nested, -->

<!--                             gbm = map2(train_data, "gbm", model_caret)) -->

<!-- ``` -->

[TODO - Here could also mention using preProcess function to do things like center and scale data ]

## Make Predictions

[TODO]

... first one example...

```{r}
predict(object  = cryptodata_nested$lm_model[[1]],
              newdata = cryptodata_nested$test_data[[1]],
              na.action = na.pass)
```

... now make function to use for map

```{r}
make_predictions <- function(model, test){
  
  predict(object  = model, newdata = test, na.action = na.pass)
  
}
```

And use map2() to use it to make predictions and create new columns for both the test data and the holdout:

```{r}
cryptodata_nested <- mutate(cryptodata_nested, 
                            lm_test_predictions =  map2(lm_model,
                                                   test_data,
                                                   make_predictions),
                            
                            lm_holdout_predictions =  map2(lm_model,
                                                      holdout_data,
                                                      make_predictions))
```

We can view the results:

```{r}
select(cryptodata_nested, lm_test_predictions, lm_holdout_predictions)
```

Now we can do the same for the rest of the models:

```{r}
cryptodata_nested <- mutate(cryptodata_nested, 
                            # XGBoost:
                            xgb_test_predictions =  map2(xgb_model,
                                                    test_data,
                                                    make_predictions),
                            # holdout
                            xgb_holdout_predictions =  map2(xgb_model,
                                                       holdout_data,
                                                       make_predictions),
                            # XGBoost Trees:
                            xgbTree_test_predictions =  map2(xgbTree_model,
                                                        test_data,
                                                        make_predictions),
                            # holdout
                            xgbTree_holdout_predictions =  map2(xgbTree_model,
                                                           holdout_data,
                                                           make_predictions),
                            # Neural Network:
                            nnet_test_predictions =  map2(nnet_model,
                                                     test_data,
                                                     make_predictions),
                            # holdout
                            nnet_holdout_predictions =  map2(nnet_model,
                                                        holdout_data,
                                                        make_predictions))
```

Done with the parallel processing now:

```{r stop_parallel_processing}
stopCluster(cl)
```

## Traditional Timeseries

<!-- [TODO - HERE TALK ABOUT ARIMA AND ETS AND MAKE MODELS! KEEP SAME STRUCTURE AND WILL BE ABLE TO DO postResample()] -->

<!-- [TODO - AFTERWARDS ALSO NEED TO ADD NEW STEPS INTO NEXT SECTION!] -->



<!-- ### Convert to tsibble {#convert-to-tsibble-pred-model} -->

<!-- Repeat the steps we performed in the [Data Prep section to convert the data to the [**tsibble**]{style="color: blue;"} format](#convert-to-tsibble): -->

<!-- STEPS BELOW NEED TO BE CONVERTED FOR NESTED DATA USING FUNCTIONAL PROGRAMMING -->
<!-- ```{r} -->
<!-- cryptodata <- mutate(cryptodata, ts_index = anytime(paste0(pkDummy,':00:00'))) -->
<!-- # Distinct data by ts_index and symbol -->
<!-- cryptodata <- distinct(cryptodata, symbol, ts_index, .keep_all=TRUE) -->
<!-- # Convert to tsibble -->
<!-- cryptodata <- as_tsibble(cryptodata, index = ts_index, key = symbol) -->
<!-- ``` -->





